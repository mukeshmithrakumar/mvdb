{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed93359d",
   "metadata": {},
   "source": [
    "# Introduction to Faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b43eb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46fc113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6822bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3b930ff",
   "metadata": {},
   "source": [
    "## Introduction to Faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a508d6",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac89e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [\n",
    "#     \"../data/2012_MSRpar.train.tsv\",\n",
    "#     \"../data/2012_MSRpar.test.tsv\",\n",
    "#     \"../data/2012_OnWN.test.tsv\",\n",
    "#     \"../data/2013_OnWN.test.tsv\",\n",
    "#     \"../data/2014_OnWN.test.tsv\",\n",
    "#     \"../data/2014_images.test.tsv.txt\",\n",
    "#     \"../data/2015_images.test.tsv\",\n",
    "# ]\n",
    "\n",
    "# sentences = []\n",
    "# for d in data:\n",
    "#     print(f\"path: {d}\")\n",
    "#     pl_data = pl.read_csv(d, separator=\"\\t\", has_header=False, quote_char=None, ignore_errors=True)\n",
    "#     sentences.extend(pl_data['column_1'].to_list())\n",
    "#     sentences.extend(pl_data['column_2'].to_list())\n",
    "\n",
    "# len(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be68ca6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_1</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;A group of four children danci…</td></tr><tr><td>&quot;The Conference Board said its …</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 1)\n",
       "┌─────────────────────────────────┐\n",
       "│ column_1                        │\n",
       "│ ---                             │\n",
       "│ str                             │\n",
       "╞═════════════════════════════════╡\n",
       "│ A group of four children danci… │\n",
       "│ The Conference Board said its … │\n",
       "└─────────────────────────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df = pl.read_csv(\"../data/sentences.txt\", separator=\"\\n\", quote_char=None, has_header=False)\n",
    "sentences_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abc43172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A group of four children dancing in a backyard.',\n",
       " 'The Conference Board said its measure of business confidence, which had fallen to 53 in the first quarter of 2003, improved to 60 in the most recent second quarter.',\n",
       " 'a person eating a meal, often in a restaurant',\n",
       " 'When you crossed the line, you violated the constitutional right,\" said Charles Weisselberg, who teaches law at the University of California, Berkeley.',\n",
       " \"Ross Garber, Rowland's legal counsel, said the governor would have no comment on the condo deal.\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sentences_df['column_1'].to_list()\n",
    "print(len(sentences))\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00cf088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14504\n"
     ]
    }
   ],
   "source": [
    "sentences = [word for word in list(set(sentences)) if type(word) is str]\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab907088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74877d60",
   "metadata": {},
   "source": [
    "### Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82a5fe1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14504, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ece473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/sentence_embeddings.npy\", sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f15306f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14504, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "sentence_embeddings = np.load(\"../data/sentence_embeddings.npy\")\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d018e",
   "metadata": {},
   "source": [
    "### IndexFlatL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0eb364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = sentence_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69742e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.add(sentence_embeddings)\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b328e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then search given a query `xq` and number of nearest neigbors to return `k`.\n",
    "k = 4\n",
    "xq = model.encode([\"Someone sprints with a football\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f4349cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10382  7600  7312  4212]]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 12.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbacac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A little boy is kicking up his feet in the water.\n",
      "Nobody is in front of the colorful building\n",
      "A football player is running past an official carrying a football\n",
      "Two girls are playing inside a jumper house\n"
     ]
    }
   ],
   "source": [
    "rows = I[0].tolist()\n",
    "print(*[sentences[idx] for idx in rows], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01acee13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 4 vectors to return (k) - so we initialize a zero array to hold them\n",
    "vecs = np.zeros((k, d))\n",
    "# then iterate through each ID from I and add the reconstructed vector to our zero-array\n",
    "for i, val in enumerate(rows):\n",
    "    vecs[i, :] = index.reconstruct(val)\n",
    "\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d955860",
   "metadata": {},
   "source": [
    "### Partitioning The Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102d8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlist = 50 # how many cells\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
    "print(index.is_trained)\n",
    "\n",
    "# since we added clustering, we are going to train the index\n",
    "index.train(sentence_embeddings)\n",
    "print(index.is_trained)\n",
    "\n",
    "index.add(sentence_embeddings)\n",
    "print(index.ntotal)  # number of embeddings indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b4b0dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4586 10252 12465   190]]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3fbf8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A group of football players is running in the field\n",
      "A group of people playing football is running in the field\n",
      "Two groups of people are playing football\n",
      "A person playing football is running past an official carrying a football\n"
     ]
    }
   ],
   "source": [
    "rows = I[0].tolist()\n",
    "print(*[sentences[idx] for idx in rows], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "457b47f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nq: 1\n",
      "nlist: 1\n",
      "ndis: 272\n",
      "nheap: 21\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "faiss.cvar.indexIVF_stats.reset()\n",
    "index.nprobe = 1\n",
    "D, I = index.search(xq, k)\n",
    "print(\"nq:\", faiss.cvar.indexIVF_stats.nq)\n",
    "print(\"nlist:\", faiss.cvar.indexIVF_stats.nlist)\n",
    "print(\"ndis:\", faiss.cvar.indexIVF_stats.ndis)        # distance computations\n",
    "print(\"nheap:\", faiss.cvar.indexIVF_stats.nheap_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5020de4",
   "metadata": {},
   "source": [
    "### Vector Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71295e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44000933,  0.3376906 , -0.30594134,  0.21360028, -0.3306173 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can't directly recontsruct because there is no direct mapping between the original vectors\n",
    "# and their index position due to the addition of the IVF step.\n",
    "# so we first create the direct mappings\n",
    "index.make_direct_map()\n",
    "index.reconstruct(7460)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea198cb",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c37355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "14504\n"
     ]
    }
   ],
   "source": [
    "nlist = 50 # how many cells\n",
    "m = 8 # number of centroid IDs in final compressed vectors\n",
    "bits = 8 # number of bits in each centroid\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(d) # we keep the same L2 distance flat index\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, bits)\n",
    "print(index.is_trained)\n",
    "index.train(sentence_embeddings)\n",
    "print(index.is_trained)\n",
    "index.add(sentence_embeddings)\n",
    "print(index.ntotal)  # number of embeddings indexed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b95aef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  190   399  8328 12465]]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 984 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index.nprobe = 10  # align to previous IndexIVFFlat nprobe value\n",
    "D, I = index.search(xq, k)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb761975",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Indexes for Similarity Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffccbe40",
   "metadata": {},
   "source": [
    "### Indexes in Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08242d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using the Sift1M dataset\n",
    "# http://corpus-texmex.irisa.fr/\n",
    "\n",
    "import shutil\n",
    "import urllib.request as request\n",
    "from contextlib import closing\n",
    "\n",
    "# first we download the Sift1M dataset\n",
    "with closing(request.urlopen('ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz')) as r:\n",
    "    with open('sift.tar.gz', 'wb') as f:\n",
    "        shutil.copyfileobj(r, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b5b37598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukes\\AppData\\Local\\Temp\\ipykernel_29264\\2915867793.py:5: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall()\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "# the download leaves us with a tar.gz file, we unzip it\n",
    "tar = tarfile.open('../data/sift.tar.gz', \"r:gz\")\n",
    "tar.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "25622f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# now define a function to read the fvecs file format of Sift1M dataset\n",
    "def read_fvecs(fp):\n",
    "    a = np.fromfile(fp, dtype='int32')\n",
    "    d = a[0]\n",
    "    return a.reshape(-1, d + 1)[:, 1:].copy().view('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "398193b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128) (1000000, 128)\n"
     ]
    }
   ],
   "source": [
    "# data we will search through\n",
    "xb = read_fvecs('../data/sift/sift_base.fvecs')  # 1M samples\n",
    "# also get some query vectors to search with\n",
    "xq = read_fvecs('../data/sift/sift_query.fvecs')\n",
    "# take just one query (there are many in sift_learn.fvecs)\n",
    "xq = xq[0].reshape(1, xq.shape[1])\n",
    "print(xq.shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f70be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 128  # dimensionality of Sift1M data\n",
    "k = 10  # number of nearest neighbors to return\n",
    "\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(xb)\n",
    "D, I = index.search(xq, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9a4c3",
   "metadata": {},
   "source": [
    "There are two primary approaches to make search faster:\n",
    "* Reduce vector size - through dimensionality reduction or reducing the number of bits representing our vectors values.\n",
    "* Reduce search scope - we can do this by clustering or organizing vectors into tree structures based on certain attributes, similarity, or distance - and restricting our search to closest clusters or filter through most similar branches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2e357e",
   "metadata": {},
   "source": [
    "### Locality Sensitive Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a8526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbits = d*4  # resolution of bucketed vectors\n",
    "# initialize index and add vectors\n",
    "index = faiss.IndexLSH(d, nbits)\n",
    "index.add(xb)\n",
    "# and search\n",
    "D, I = index.search(xq, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f06f2e",
   "metadata": {},
   "source": [
    "Our nbits argument refers to the 'resolution' of the hashed vectors. A higher value means greater accuracy at the cost of more memory and slower search speeds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3186cc7",
   "metadata": {},
   "source": [
    "### Hierarchical Navigable Small World Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8dfcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set HNSW index parameters\n",
    "M = 64  # number of connections each vertex will have\n",
    "ef_search = 32  # depth of layers explored during search\n",
    "ef_construction = 64  # depth of layers explored during index construction\n",
    "\n",
    "# initialize index (d == 128)\n",
    "index = faiss.IndexHNSWFlat(d, M)\n",
    "# set efConstruction and efSearch parameters\n",
    "index.hnsw.efConstruction = ef_construction\n",
    "index.hnsw.efSearch = ef_search\n",
    "# add data to index\n",
    "index.add(xb)\n",
    "\n",
    "# search as usual\n",
    "D, I = index.search(xq, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cadcca5",
   "metadata": {},
   "source": [
    "Here, we have three key parameters for modifying our index performance.\n",
    "* M - the number of nearest neighbors that each vertex will connect to.\n",
    "* efSearch - how many entry points will be explored between layers during the search.\n",
    "* efConstruction - how many entry points will be explored when building the index.\n",
    "\n",
    "M and efSearch have a larger impact on search-time - efConstruction primarily increases index construction time (meaning a slower index.add), but at higher M values and higher query volume we do see an impact from efConstruction on search-time too.\n",
    "\n",
    "HNSW gives us great search-quality at very fast search-speeds - but there’s always a catch - HNSW indexes take up a significant amount of memory. Using an M value of 128 for the Sift1M dataset requires upwards of 1.6GB of memory. However, we can increase our other two parameters - efSearch and efConstruction with no effect on the index memory footprint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4015d6",
   "metadata": {},
   "source": [
    "## Locality Sensitive Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117fce6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec86bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86f836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1cf29e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc52bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ca5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba52f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd8fa797",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "missing-semester",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
